# -*- coding: utf-8 -*-
"""
Created on Tue Nov 15 14:21:43 2016

@author: bec
"""
import os
import becgis
from dateutil.relativedelta import relativedelta
import datetime
import numpy as np
import calendar
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.lines as mlines
import matplotlib.patches as mpatches
import csv
import get_dictionaries as gd
import wa

def create_sheet3(complete_data, metadata, output_dir):
    
    output_dir = os.path.join(output_dir, metadata['name'])
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    HIWC_dict = gd.get_hi_and_ec()
    wp_y_irrigated_dictionary, wp_y_rainfed_dictionary, wp_y_non_crop_dictionary = gd.get_sheet3_empties()
    years = dict()

    LULC = becgis.OpenAsArray(metadata['lu'], nan_values = True)
    
    for crop in metadata['crops']:
        if crop[4] in LULC:
            start_dates, end_dates = import_growing_seasons(crop[0])
            result_seasonly = calc_Y_WP_seasons(start_dates, end_dates, metadata['lu'], crop[4], crop[1], complete_data['etg'][0], complete_data['etg'][1], complete_data['etb'][0], complete_data['etb'][1], complete_data['ndm'][0], complete_data['ndm'][1], complete_data['p'][0], complete_data['p'][1], os.path.join(output_dir, 'WP_Y_Seasonly_csvs'), HIWC_dict, ab = (1.0,0.9))
            result = calc_Y_WP_year(result_seasonly, os.path.join(output_dir, 'WP_Y_Yearly_csvs'), crop[1])
            plot_Y_WP(result, os.path.join(output_dir,'WP_Y_Yearly_graphs'), croptype = crop[1], catchment_name = metadata['name'], filetype = 'jpg')
            plot_Y_WP(result_seasonly, os.path.join(output_dir,'WP_Y_Seasonly_graphs'), croptype = crop[1], catchment_name = metadata['name'], filetype = 'jpg')
            if crop[4] > 50:
                wp_y_irrigated_dictionary[crop[2]][crop[3]] = result
            else:
                wp_y_rainfed_dictionary[crop[2]][crop[3]] = result
            years[crop[4]] = [date.year for date in read_csv(result)[0]][1:]
        else:
            print "skipping crop with lu-class {0}, not on LU-map".format(crop[4])
            continue
    
    if metadata['non_crop'] is not None:
        for i, non_crop in enumerate([metadata['non_crop']['meat'], metadata['non_crop']['milk'], metadata['non_crop']['aquaculture'], metadata['non_crop']['timber']]):
            years[i] = [date.year for date in read_csv(non_crop)[0]][1:]
            crp = ['Meat', 'Milk', 'Aquaculture', 'Timber']
            plot_Y_WP(result, os.path.join(output_dir,'WP_Y_Yearly_graphs'), croptype = crp[i], catchment_name = metadata['name'], filetype = 'jpg')

    years = becgis.CommonDates(years.values())
    
    if metadata['non_crop'] is not None:
        wp_y_non_crop_dictionary['Livestock']['Meat'] = metadata['non_crop']['meat']
        wp_y_non_crop_dictionary['Livestock']['Milk'] = metadata['non_crop']['milk']
        wp_y_non_crop_dictionary['Fish (Aquaculture)']['-'] = metadata['non_crop']['aquaculture']
        wp_y_non_crop_dictionary['Timber']['-'] = metadata['non_crop']['timber']

    for year in years:
        csv_fh_a, csv_fh_b = create_sheet3_csv(wp_y_irrigated_dictionary, wp_y_rainfed_dictionary, wp_y_non_crop_dictionary, year, output_dir)
        output_fh_a = csv_fh_a[:-3] + 'pdf'
        output_fh_b = csv_fh_b[:-3] + 'pdf'
        sheet3a_fh, sheet3b_fh = wa.Sheets.create_sheet3(metadata['name'], str(year), ['km3/year', 'kg/ha/year', 'kg/m3'], [csv_fh_a, csv_fh_b], [output_fh_a, output_fh_b])
     
    return complete_data

def create_sheet3_csv(wp_y_irrigated_dictionary, wp_y_rainfed_dictionary, wp_y_non_crop_dictionary, year, output_dir):
    """
    Creates a csv file that can be used to create sheet3b.
    
    Parameters
    ----------
    wp_y_irrigated_dictionary : dict
        Dictionary in which the filehandles pointing to csv-files containing
        the Yield and WP values are specified, as generated by calc_Y_WP_year.
    wp_y_rainfed_dictionary : dict
        Dictionary in which the filehandles pointing to csv-files containing
        the Yield and WP values are specified, as generated by calc_Y_WP_year.
    wp_y_non_crop_dictionary : dict
        Dictionary in which the filehandles pointing to csv-files containing
        the Yield and WP values are specified. See examples.
    year : int
        Variable specifying for what year the csv needs to be generated.
    output_dir : str
        String pointing to folder to store results
        
    Returns
    -------
    output_csv_fh_b : str
        Filehandle pointing to the generated output.
        
    Examples
    --------
    >>> results_rice = r'D:\\project_ADB\\Catchments\\VGTB\\sheet3\\Yearly_Yields_WPs_Rice - Irrigated.csv'
    
    >>> wp_y_irrigated_dictionary = {
            'Cereals': {'-': result_rice},
            'Non-cereals': {'Root/tuber-crops':None, 'Leguminous-crops':None, 'Sugar-crops':None, 'Merged':None},
            'Fruit & vegetables': {'Vegetables&Melons':None, 'Fruits&Nuts':None, 'Merged':None},
            'Oilseeds': {'-': None},
            'Feed crops': {'-': None},
            'Beverage crops': {'-': None},
            'Other crops': {'-': None}}

    >>> wp_y_rainfed_dictionary = {
            'Cereals': {'-':None},
            'Non-cereals': {'Root/tuber-crops':None, 'Leguminous-crops':None, 'Sugar-crops':None, 'Merged':None},
            'Fruit & vegetables': {'Vegetables&Melons':None, 'Fruits&Nuts':None, 'Merged':None},
            'Oilseeds': {'-': None},
            'Feed crops': {'-': None},
            'Beverage crops': {'-': None},
            'Other crops': {'-': None}}

    >>> wp_y_non_crop_dictionary = {
            'Livestock': {'Meat':None, 'Milk':None},
            'Fish (Aquaculture)': {'-':None},
            'Timber': {'-':None}}
    """
    output_dir = os.path.join(output_dir, 'sheet3')
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    output_csv_fh_b = os.path.join(output_dir, 'sheet3b_{0}.csv'.format(year))
    output_csv_fh_a = os.path.join(output_dir, 'sheet3a_{0}.csv'.format(year))
    
    first_row_b = ["USE","CLASS","SUBCLASS","TYPE","SUBTYPE","LAND_PRODUCTIVITY","WATER_PRODUCTIVITY"]
    first_row_a = ["USE","CLASS","SUBCLASS","TYPE","SUBTYPE","WATER_CONSUMPTION"]
    
    csv_file_b = open(output_csv_fh_b, 'wb')
    writer_b = csv.writer(csv_file_b, delimiter=';')
    writer_b.writerow(first_row_b)
    
    csv_file_a = open(output_csv_fh_a, 'wb')
    writer_a = csv.writer(csv_file_a, delimiter=';')
    writer_a.writerow(first_row_a)
    
    for TYPE in wp_y_irrigated_dictionary.keys():
        for SUBTYPE in wp_y_irrigated_dictionary[TYPE].keys():
            if type(wp_y_irrigated_dictionary[TYPE][SUBTYPE]) is type(None):
                writer_b.writerow(["CROP","IRRIGATED","Yield rainfall",TYPE,SUBTYPE,"nan","nan"])
                writer_b.writerow(["CROP","IRRIGATED","Incremental yield",TYPE,SUBTYPE,"nan","nan"])
                writer_b.writerow(["CROP","IRRIGATED","Total yield",TYPE,SUBTYPE,"nan","nan"])
                writer_a.writerow(["CROP","IRRIGATED","ET rainfall",TYPE,SUBTYPE,"nan"])
                writer_a.writerow(["CROP","IRRIGATED","Incremental ET",TYPE,SUBTYPE,"nan"])
            else:                
                start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WCblue, WCgreen = read_csv(wp_y_irrigated_dictionary[TYPE][SUBTYPE])
                mask = start_dates == datetime.date(year,1,1)
                writer_b.writerow(["CROP","IRRIGATED","Yield rainfall",TYPE,SUBTYPE,Ypr[mask][0],WPgreen[mask][0]])
                writer_b.writerow(["CROP","IRRIGATED","Incremental yield",TYPE,SUBTYPE,Yirr[mask][0],WPblue[mask][0]])
                writer_b.writerow(["CROP","IRRIGATED","Total yield",TYPE,SUBTYPE,Y[mask][0],WP[mask][0]])              
                writer_a.writerow(["CROP","IRRIGATED","ET rainfall",TYPE,SUBTYPE,WCgreen[mask][0]])
                writer_a.writerow(["CROP","IRRIGATED","Incremental ET",TYPE,SUBTYPE,WCblue[mask][0]])
                
    for TYPE in wp_y_rainfed_dictionary.keys():
        for SUBTYPE in wp_y_rainfed_dictionary[TYPE].keys():
            if type(wp_y_rainfed_dictionary[TYPE][SUBTYPE]) is type(None):
                writer_b.writerow(["CROP","RAINFED","Yield",TYPE,SUBTYPE,"nan","nan"])
                writer_a.writerow(["CROP","RAINFED","ET",TYPE,SUBTYPE,"nan"])
            else:
                start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WCblue, WCgreen  = read_csv(wp_y_rainfed_dictionary[TYPE][SUBTYPE])
                mask = start_dates == datetime.date(year,1,1)
                writer_b.writerow(["CROP","RAINFED","Yield",TYPE,SUBTYPE,Y[mask][0],WP[mask][0]])
                writer_a.writerow(["CROP","RAINFED","ET",TYPE,SUBTYPE,WC[mask][0]])
    
    for TYPE in wp_y_non_crop_dictionary.keys():
        for SUBTYPE in wp_y_non_crop_dictionary[TYPE].keys():
            if type(wp_y_non_crop_dictionary[TYPE][SUBTYPE]) is type(None):
                writer_b.writerow(["NON-CROP","RAINFED","Yield",TYPE,SUBTYPE,"nan","nan"])
                writer_b.writerow(["NON-CROP","IRRIGATED","Yield rainfall",TYPE,SUBTYPE,"nan","nan"])
                writer_b.writerow(["NON-CROP","IRRIGATED","Incremental yield",TYPE,SUBTYPE,"nan","nan"])
                writer_b.writerow(["NON-CROP","IRRIGATED","Total yield",TYPE,SUBTYPE,"nan","nan"])
                if TYPE is not 'Livestock':
                    writer_a.writerow(["NON-CROP","RAINFED","ET",TYPE,SUBTYPE,"nan"])
                    writer_a.writerow(["NON-CROP","IRRIGATED","ET rainfall",TYPE,SUBTYPE,"nan"])
                    writer_a.writerow(["NON-CROP","IRRIGATED","Incremental ET",TYPE,SUBTYPE,"nan"])
                else:
                    continue
            else:
                start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WCblue, WCgreen  = read_csv(wp_y_non_crop_dictionary[TYPE][SUBTYPE])
                mask = start_dates == datetime.date(year,1,1)
                if TYPE is not 'Livestock':
                    writer_b.writerow(["NON-CROP","RAINFED","Yield",TYPE,SUBTYPE,Y[mask][0],WP[mask][0]])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Yield rainfall",TYPE,SUBTYPE,"nan","nan"])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Incremental yield",TYPE,SUBTYPE,"nan","nan"])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Total yield",TYPE,SUBTYPE,"nan","nan"])
                    writer_a.writerow(["NON-CROP","RAINFED","ET",TYPE,SUBTYPE,WC[mask][0]])
                    writer_a.writerow(["NON-CROP","IRRIGATED","ET rainfall",TYPE,SUBTYPE,"nan"])
                    writer_a.writerow(["NON-CROP","IRRIGATED","Incremental ET",TYPE,SUBTYPE,"nan"])
                else:
                    writer_b.writerow(["NON-CROP","RAINFED","Yield",TYPE,SUBTYPE,Y[mask][0],"nan"])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Yield rainfall",TYPE,SUBTYPE,"nan","nan"])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Incremental yield",TYPE,SUBTYPE,"nan","nan"])
                    writer_b.writerow(["NON-CROP","IRRIGATED","Total yield",TYPE,SUBTYPE,"nan","nan"])
    
    csv_file_b.close()
    
    return output_csv_fh_a, output_csv_fh_b
    
def splitET_BlueGreen(et_fhs, et_dates, etref_fhs, etref_dates, p_fhs, p_dates, lu_fh, output_dir, 
                      moving_avg_length = 7, green_blue_categories = None, plot_graph = True, 
                      method = 'tail', scale = 1.1, basin = ''):
    """
    Splits georeferenced evapotranspiration rastermaps into blue and green evapotranspiration maps.
    
    Parameters
    ----------
    et_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced evapotranspiration rastermaps.
    et_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in et_fhs. Length should be equal
        to et_fhs.
    etref_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced reference evapotranspiration rastermaps.
    etref_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etref_fhs. Length should be equal
        to etref_fhs.
    p_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced precipitation rastermaps.
    p_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in p_fhs. Length should be equal
        to p_fhs.
    lu_fh : str
        Filehandle pointing to a landusemap.
    output_dir : str
        String pointing to a folder to store output
    moving_average_length : int or dict, optional
        Number of months used to calculate averages. Default is 7. In case a dictionary is provided,
        different lengths can be specified per landuse category.
    green_blue_categories : dict
        Dictionary indicating which landuseclasses belong to which category.
    plot_graph : boolean, optional
        Create a graph of the ETblue and ETgreen timeseries when True. Default is True.
    method : str, optional
        Method to calculate the average for ET0 and P. Default is 'tail', other option is 'central'.
    scale : float, optional
        Increase the budyko water-limit. Default is 1.1.
        
    Returns
    -------
    etblue_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced blue-evapotranspiration rastermaps.
    etblue_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etblue_fhs. Length is equal
        to et_fhs.
    etgreen_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced green-evapotranspiration rastermaps.
    etgreen_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etgreen_fhs. Length is equal
        to etgreen_fhs.
    """
    becgis.AssertProjResNDV([et_fhs, etref_fhs, p_fhs])
    driver, NDV, xsize, ysize, GeoT, Projection = becgis.GetGeoInfo(et_fhs[0])
    
    LULC = becgis.OpenAsArray(lu_fh, nan_values = True)
     
    common_dates = becgis.CommonDates([et_dates, etref_dates, p_dates])
    
    if type(moving_avg_length) is dict:
        max_moving_avg_length = np.max(moving_avg_length.values())
        becgis.plot_category_areas(lu_fh, green_blue_categories, os.path.join(output_dir, 'Landuse_Areas.jpg'), area_treshold = 0.01)
        if method == 'central':
            dts = common_dates[(max_moving_avg_length-1)/2:len(common_dates)-(max_moving_avg_length-1)/2]
            for value in moving_avg_length.values():
                assert (value % 2) != 0, "Please provide only uneven lengths when using method 'central'"
        elif method == 'tail':
            dts = common_dates[max_moving_avg_length-1:]
        assert green_blue_categories is not None, "Please provide a dictionary specifying the different landusecategories."
    else:
        max_moving_avg_length = moving_avg_length
        if method == 'central':
            dts = common_dates[(max_moving_avg_length-1)/2:len(common_dates)-(max_moving_avg_length-1)/2]
            assert (moving_avg_length % 2) != 0, "Please provide a uneven moving average length."
        elif method == 'tail':
            dts = common_dates[max_moving_avg_length-1:]
       
    becgis.AssertMissingDates(common_dates, timescale = 'months')
    
    directory_etgreen = os.path.join(output_dir, "etg")
    if not os.path.exists(directory_etgreen):
        os.makedirs(directory_etgreen)
    
    directory_etblue = os.path.join(output_dir, "etb")
    if not os.path.exists(directory_etblue):
        os.makedirs(directory_etblue)
        
    print("Starting calculation of Blue and Green ET for {0} months between {1} and {2}.".format(len(dts), dts[0], dts[-1]))
    
    if plot_graph:
        etblue = np.array([])
        etgreen = np.array([])
        et = np.array([])
        p = np.array([])
        pavg = np.array([])
    
        rows = 4
        cols = 3
        
        row_no = np.sort(range(rows)*cols)
        col_no = range(cols)*rows
        
        stats = becgis.ZonalStats(p_fhs, p_dates, output_dir, 'Precipitation', '[mm/month]', basin)
        vmax = np.round((stats[0]*1.1)/10)*10
        
        directory_budyko = os.path.join(output_dir, "Budyko_Curves")
        if not os.path.exists(directory_budyko):
            os.makedirs(directory_budyko)
    
    for date in dts:
        
        P = becgis.OpenAsArray(p_fhs[p_dates == date][0], nan_values = True)
        ET  = becgis.OpenAsArray(et_fhs[et_dates == date][0], nan_values = True)
        ETREF = becgis.OpenAsArray(etref_fhs[etref_dates == date][0], nan_values = True)
        
        if type(moving_avg_length) is dict:
            Pavg = becgis.MaskedMovingAverage(date, p_fhs, p_dates, lu_fh, moving_avg_length, green_blue_categories, method = method)
            ETREFavg = becgis.MaskedMovingAverage(date, etref_fhs, etref_dates, lu_fh, moving_avg_length, green_blue_categories, method = method)    
            lu_dependent = True
        else:
            Pavg = becgis.MovingAverage(date, p_fhs, p_dates, moving_avg_length = moving_avg_length, method = method)
            ETREFavg = becgis.MovingAverage(date, etref_fhs, etref_dates, moving_avg_length = moving_avg_length, method = method)
            lu_dependent = False
        
        if np.all([np.any([date.month == 1, date == dts[0]]), plot_graph]):
            maxim = mayim = 0.0
            fig, axarr = plt.subplots(rows, cols, sharex=True, sharey=True, figsize = (8.27, 11.69))
            title = 'Budyko Curves \n (P_{0}, {1} months, lu_dependent: {2}, scale: {3})'.format(method, max_moving_avg_length, lu_dependent, scale)
        
        mask = np.any([np.isnan(LULC), np.isnan(ET), np.isnan(ETREF), np.isnan(P), np.isnan(Pavg), np.isnan(ETREFavg)], axis=0)
        ETREF[mask] = ETREFavg[mask] = ET[mask] = P[mask] = Pavg[mask] = np.nan
        
        phi = ETREFavg / Pavg
      
        ## Calculate Bydyko-index
        budyko = scale * np.sqrt(phi*np.tanh(1/phi)*(1-np.exp(-phi)))
         
        ETgreen = np.minimum(budyko*P,ET)
        
        ## Calculate blue ET
        ETblue = ET - ETgreen
        
        ## Save ETgreen-map
        output_fh = os.path.join(directory_etgreen, 'ETgreen_{0}{1}.tif'.format(date.year,str(date.month).zfill(2)))
        becgis.CreateGeoTiff(output_fh, ETgreen, driver, NDV, xsize, ysize, GeoT, Projection)

        ## Save ETblue-map
        output_fh = os.path.join(directory_etblue, 'ETblue_{0}{1}.tif'.format(date.year,str(date.month).zfill(2)))
        becgis.CreateGeoTiff(output_fh, ETblue, driver, NDV, xsize, ysize, GeoT, Projection)
        
        if plot_graph:
            
            etblue = np.append(etblue, np.nanmean(ETblue))
            etgreen = np.append(etgreen, np.nanmean(ETgreen))
            et = np.append(et, np.nanmean(ET))
            p = np.append(p, np.nanmean(P))
            pavg = np.append(pavg, np.nanmean(Pavg))
            
            frac_ETa = ET/Pavg

            if green_blue_categories:
                from matplotlib.colors import LinearSegmentedColormap
                n_cats = len(green_blue_categories)
                clrs = ['#6bb8cc','#87c5ad', '#9ad28d', '#acd27a', '#c3b683', '#d4988b', '#b98b89', '#868583', '#497e7c',
                        '#6bb8cc','#87c5ad', '#9ad28d', '#acd27a', '#c3b683', '#d4988b', '#b98b89', '#868583', '#497e7c']
                cmap = LinearSegmentedColormap.from_list('LUC', clrs[0:n_cats], N = n_cats)
                C = np.ones_like(LULC)
                for i, key in enumerate(green_blue_categories.keys()):
                    classes = green_blue_categories[key]
                    mask = np.logical_or.reduce([LULC == value for value in classes])
                    C[mask] += i
                vmin = 0.5
                vmax = vmin + n_cats
                
            else:
                C = P
                vmin = 0
                cmap = 'viridis'
                
            im = axarr[row_no[date.month-1],col_no[date.month-1]].scatter(phi, frac_ETa, c=C, marker = '.', alpha=1.0, lw=0.0, cmap=cmap, vmin = vmin, vmax = vmax)

            maxim = np.max([maxim,np.nanmax(phi)])
            mayim = np.max([mayim,np.nanmax(frac_ETa)])
            
            axarr[row_no[date.month-1],col_no[date.month-1]].set_title('{0}'.format(date))
        
        print(date)
        
        if np.all([np.any([date.month == 12, date == dts[-1]]), plot_graph]):
            
            x = np.arange(0,maxim*1.2,0.1)
            y = scale * np.sqrt(x*np.tanh(1/x)*(1-np.exp(-x)))
            
            for row, col in zip(row_no, col_no):
                axarr[row,col].set_xlim([0,maxim*1.1])
                axarr[row,col].set_ylim([0,max(1.1,mayim*1.1)])
                im2, = axarr[row,col].plot(x,y,'-k' , label = 'Budyko Curve')
                axarr[row,col].plot(x,x*scale,'--k', label = 'Energy Limit')
                axarr[row,col].plot(x,np.ones_like(x)*scale,'--k', label = 'Water Limit')
                
                if row == max(row_no):
                    axarr[row,col].set_xlabel(r'ET0avg/Pavg')
                if col == min(col_no):
                    axarr[row,col].set_ylabel(r'ETa/Pavg or Max_ETg/P')
            
            fig.subplots_adjust(right=0.8)
            cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])
            
            if green_blue_categories:
                cbar = fig.colorbar(im, cax=cbar_ax)
                cbar.set_ticks(range(1,n_cats + 1))
                cbar.set_ticklabels(green_blue_categories.keys())
            else:
                cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])
                cbar = fig.colorbar(im, cax=cbar_ax, label = 'P [mm/month]')
            
            fig.suptitle(title, fontsize = 13)
            fig.legend([im, im2], ('ETa/Pavg', 'Max_ETgreen/P'), 'lower center', ncol =2, fancybox=True, shadow=True)
            fig.autofmt_xdate(bottom=0.2, rotation=30, ha='right')
            
            print("Saving Budyko plot for {0}...".format(date.year))
            
            plt.savefig(os.path.join(directory_budyko, 'bc{0}_{1}months_{2}_lu{3}.jpg'.format(date.year, max_moving_avg_length, method, str(lu_dependent))))
            plt.close(fig)
            
    etblue_fhs, etblue_dates, etblue_years, etblue_months, etblue_days = becgis.SortFiles(directory_etblue, [-10,-6], month_position = [-6,-4])
    etgreen_fhs, etgreen_dates, etgreen_years, etgreen_months, etgreen_days = becgis.SortFiles(directory_etgreen,  [-10,-6], month_position = [-6,-4]) 
    
    if plot_graph:
        fig = plt.figure(figsize = (10,10))
        plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
        ax = fig.add_subplot(111)
        ax.plot(dts, et, color = 'k')
        ax.patch.set_visible(False)
        ax.set_title('Average ET and ETblue and ETgreen fractions')
        ax.set_ylabel('ET [mm/month]')
        ax.patch.set_visible(True)
        ax.fill_between(dts, et, color = '#a3db76', label = 'ETgreen')
        ax.fill_between(dts, etblue, color = '#6bb8cc', label = 'ETblue')
        ax.scatter(dts, et, color = 'k')
        ax.legend(loc = 'upper left',fancybox=True, shadow=True)
        fig.autofmt_xdate()
        fig.suptitle('P_{0}, {1} months, lu_dependent: {2}, scale: {3}'.format(method, max_moving_avg_length, lu_dependent, scale))
        ax.set_xlim([dts[0], dts[-1]])
        ax.set_ylim([0, max(et) *1.2])
        ax.set_xlabel('Time')
        [j.set_zorder(10) for j in ax.spines.itervalues()]
        plt.savefig(os.path.join(output_dir,'ETbluegreen_{0}months_{1}_lu{2}.jpg'.format(max_moving_avg_length, method, str(lu_dependent))))
        plt.close(fig)
        
    if plot_graph:
        fig = plt.figure(figsize = (10,10))
        plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
        ax = fig.add_subplot(111)
        ax.plot(dts, p, color = 'k')
        ax.patch.set_visible(False)
        ax.set_title('(Averaged) Precipitation')
        ax.set_ylabel('P [mm/month]')
        ax.patch.set_visible(True)
        ax.fill_between(dts, p, color = '#6bb8cc', label = 'Actual P')
        ax.scatter(dts, p, color = 'k')
        ax.plot(dts, pavg, '--k', label = 'Average P')
        ax.legend(loc = 'upper left',fancybox=True, shadow=True)
        fig.autofmt_xdate()
        fig.suptitle('P_{0}, {1} months, lu_dependent: {2}'.format(method, max_moving_avg_length, lu_dependent))
        ax.set_xlim([dts[0], dts[-1]])
        ax.set_ylim([0, max([max(pavg),max(p)]) *1.2])
        ax.set_xlabel('Time')
        [j.set_zorder(10) for j in ax.spines.itervalues()]
        plt.savefig(os.path.join(output_dir,'Paveraged_{0}months_{1}_lu{2}.jpg'.format(max_moving_avg_length, method, str(lu_dependent))))
        plt.close(fig)
        
    return etblue_fhs, etblue_dates, etgreen_fhs, etgreen_dates  
        
def splitET_BlueGreen_old(et_fhs, et_dates, etref_fhs, etref_dates, p_fhs, p_dates, lu_fh, output_dir, moving_avg_length = 1, green_blue_categories = None, plot_graph = True):
    """
    Splits georeferenced evapotranspiration rastermaps into blue and green evapotranspiration maps.
    
    Parameters
    ----------
    et_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced evapotranspiration rastermaps.
    et_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in et_fhs. Length should be equal
        to et_fhs.
    etref_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced reference evapotranspiration rastermaps.
    etref_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etref_fhs. Length should be equal
        to etref_fhs.
    p_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced precipitation rastermaps.
    p_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in p_fhs. Length should be equal
        to p_fhs.
    lu_fh : str
        Filehandle pointing to a landusemap.
    output_dir : str
        String pointing to a folder to store output
    moving_average_length : int or dict, optional
        Length indicates how long the trailing average for reference evapotranspiration and
        precipitation is. For each pixel, the average precipitation is compared to the
        current precipitation, when the average is larger than the current, the average values are
        used. Otherwise the current reference evapotranspiration and precipitation are used. In case a dictionary is
        provided, individual lengths can be selected per landuse category. The landuse categories are defined in
        green_blue_categories.
        Default is 1.
    green_blue_categories : dict
        Dictionary indicating which landuseclasses belong to which category.
    plot_graph : boolean, optional
        Create a graph of the ETblue and ETgreen timeseries when True. Default is True.
    full_averaging : boolean, optional
        Use the averaged values to determine ETblue and ETgreen for all pixels. The comparison
        between current P and average P is omitted. Default is False.
        
    Returns
    -------
    etblue_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced blue-evapotranspiration rastermaps.
    etblue_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etblue_fhs. Length is equal
        to et_fhs.
    etgreen_fhs : ndarray
        Array containing strings with filehandles pointing to georeferenced green-evapotranspiration rastermaps.
    etgreen_dates : ndarray
        Array containing datetime.date objects corresponding to the filehandles in etgreen_fhs. Length is equal
        to etgreen_fhs.
    """
    print 'WARNING: You are using a old version of Split_ETgreenblue, this version will be deleted'
    month_labels = {1:'01',2:'02',3:'03',4:'04',5:'05',6:'06',7:'07',8:'08',9:'09',10:'10',11:'11',12:'12'}
    
    becgis.AssertProjResNDV([et_fhs, etref_fhs, p_fhs])
    driver, NDV, xsize, ysize, GeoT, Projection = becgis.GetGeoInfo(et_fhs[0])
    
    LULC = becgis.OpenAsArray(lu_fh, nan_values = True)
     
    common_dates = becgis.CommonDates([et_dates, etref_dates, p_dates])
    
    if type(moving_avg_length) is dict:
        max_moving_avg_length = np.max(moving_avg_length.values())
        becgis.plot_category_areas(lu_fh, green_blue_categories, os.path.join(output_dir, 'landuse_area.jpg'), area_treshold = 0.01)
    else:
        max_moving_avg_length = moving_avg_length
    
    if max_moving_avg_length > 1:
        becgis.AssertMissingDates(common_dates, timescale = 'months')
    
    directory_etgreen = os.path.join(output_dir, "ETgreen")
    if not os.path.exists(directory_etgreen):
        os.makedirs(directory_etgreen)
    
    directory_etblue = os.path.join(output_dir, "ETblue")
    if not os.path.exists(directory_etblue):
        os.makedirs(directory_etblue)
        
    print "Starting calculation of Blue and Green ET for {0} months between {1} and {2}.".format(len(common_dates[(max_moving_avg_length - 1):]), common_dates[(max_moving_avg_length - 1):][0], common_dates[(max_moving_avg_length - 1):][-1])
    
    if plot_graph:
        etblue = np.array([])
        etgreen = np.array([])
        et = np.array([])
    
    for date in common_dates[(max_moving_avg_length - 1):]:
        
        P = becgis.OpenAsArray(p_fhs[p_dates == date][0], nan_values = True)
        ET  = becgis.OpenAsArray(et_fhs[et_dates == date][0], nan_values = True)
        ETREF = becgis.OpenAsArray(etref_fhs[etref_dates == date][0], nan_values = True)
        
        if type(moving_avg_length) is dict:
            Pavg = becgis.MaskedMovingAverage(date, p_fhs, p_dates, lu_fh, moving_avg_length, green_blue_categories)
            ETREFavg = becgis.MaskedMovingAverage(date, etref_fhs, etref_dates, lu_fh, moving_avg_length, green_blue_categories)     
        else:
            Pavg = becgis.MovingAverage(date, p_fhs, p_dates, moving_avg_length = moving_avg_length)
            ETREFavg = becgis.MovingAverage(date, etref_fhs, etref_dates, moving_avg_length = moving_avg_length)
        
        mask = np.any([np.isnan(LULC), np.isnan(ET), np.isnan(ETREF), np.isnan(P), np.isnan(Pavg), np.isnan(ETREFavg)], axis=0)
        ETREF[mask] = ETREFavg[mask] = ET[mask] = P[mask] = Pavg[mask] = np.nan
        
        phi = np.where(np.greater_equal(P, Pavg), ETREF/P, ETREFavg/Pavg)
        
        ## Calculate Bydyko-index
        budyko = np.sqrt(phi*np.tanh(1/phi)*(1-np.exp(-phi)))
        
        ## Calculate green ET
        ETgreen = np.where(np.greater_equal(P, Pavg), np.minimum(1.1*budyko*P,ET), np.minimum(1.1*budyko*Pavg,ET))
        
        ## Calculate blue ET
        ETblue = ET - ETgreen
        
        ## Save ETgreen-map
        output_fh = os.path.join(directory_etgreen, 'ETgreen_{0}_{1}.tif'.format(date.year,month_labels[date.month]))
        becgis.CreateGeoTiff(output_fh, ETgreen, driver, NDV, xsize, ysize, GeoT, Projection)
            
        ## Save ETblue-map
        output_fh = os.path.join(directory_etblue, 'ETblue_{0}_{1}.tif'.format(date.year,month_labels[date.month]))
        becgis.CreateGeoTiff(output_fh, ETblue, driver, NDV, xsize, ysize, GeoT, Projection)
        
        if plot_graph:
            etblue = np.append(etblue, np.nanmean(ETblue))
            etgreen = np.append(etgreen, np.nanmean(ETgreen))
            et = np.append(et, np.nanmean(ET))
        
        if plot_graph:
            
            plt.figure(figsize = (10,10))
            plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
            
            maxim = np.nanmax(phi)
            
            x = np.arange(0,maxim*1.2,0.1)
            y = np.sqrt(x*np.tanh(1/x)*(1-np.exp(-x)))
            
            frac_ETa = np.where(np.greater_equal(P, Pavg), ET/P, ET/Pavg)    
            
            plt.plot(x,y, label = 'Budyko Curve', zorder = 10)
            plt.plot(x,x, label = 'Energy Limit', zorder = 10)
            plt.plot(x,np.ones_like(x), label = 'Water Limit', zorder =10)

            plt.title('Budyko Curve, {0}'.format(date))
            #ax.scatter(phi[np.greater_equal(P, Pavg)], frac_ETa[np.greater_equal(P, Pavg)], c=P[np.greater_equal(P, Pavg)],   marker = 'x', alpha = 0.5, label = 'P $\geq$ P_avg')
            #ax.scatter(phi[~np.greater_equal(P, Pavg)], frac_ETa[~np.greater_equal(P, Pavg)], c=P[~np.greater_equal(P, Pavg)], marker = '.', alpha = 1.0, label = 'P $<$ P_avg')
            
            plt.scatter(phi, frac_ETa, c=P, marker = '.', alpha = 1.0, lw=0.0, cmap='viridis')
            plt.colorbar(label = 'P [mm/month]' )
            ax = plt.gca()
            
            ax.set_xlim([0,np.nanmax(phi)*1.1])
            ax.set_ylim([0,max(1.1,np.nanmax(frac_ETa)*1.1)])
            ax.legend(loc = 'upper left',fancybox=True, shadow=True)
            ax.set_xlabel(r'ET0/P or ET0_avg/P_avg')
            ax.set_ylabel(r'ETA/P or ETA/P_avg')
            
            directory_budyko = os.path.join(output_dir, "budyko_curves")
            if not os.path.exists(directory_budyko):
                os.makedirs(directory_budyko)
            
            plt.savefig(os.path.join(directory_budyko, 'bc_{0}{1}.jpg'.format(date.year, str(date.month).zfill(2))))
    
    etblue_fhs, etblue_dates, etblue_years, etblue_months, etblue_days = becgis.SortFiles(directory_etblue, [-11,-7], month_position = [-6,-4])
    etgreen_fhs, etgreen_dates, etgreen_years, etgreen_months, etgreen_days = becgis.SortFiles(directory_etgreen, [-11,-7], month_position = [-6,-4])   
    
    if plot_graph:
        fig = plt.figure(figsize = (10,10))
        plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
        ax = fig.add_subplot(111)
        ax.plot(common_dates[(max_moving_avg_length - 1):], et, color = 'k')
        ax.patch.set_visible(False)
        ax.set_title('Average ET and ETblue and ETgreen fractions')
        ax.set_ylabel('ET [mm/month]')
        ax.patch.set_visible(True)
        ax.fill_between(common_dates[(max_moving_avg_length - 1):], et, color = '#a3db76', label = 'ETgreen')
        ax.fill_between(common_dates[(max_moving_avg_length - 1):], etblue, color = '#6bb8cc', label = 'ETblue')
        ax.scatter(common_dates[(max_moving_avg_length - 1):], et, color = 'k')
        ax.legend(loc = 'upper left',fancybox=True, shadow=True)
        fig.autofmt_xdate()
        ax.set_xlim([common_dates[(max_moving_avg_length - 1):][0], common_dates[(max_moving_avg_length - 1):][-1]])
        ax.set_ylim([0, max(et) *1.2])
        ax.set_xlabel('Time')
        [i.set_zorder(10) for i in ax.spines.itervalues()]
        plt.savefig(os.path.join(output_dir,'ETfractions_bluegreen_int.jpg'))
        


                
        
        
    
    return etblue_fhs, etblue_dates, etgreen_fhs, etgreen_dates           
    
def calc_Y_WP_year(csv_fh, output_dir, croptype):
    """
    Calculate yearly Yields and Water Productivities from seasonal values (created with calc_Y_WP_seasons) and store
    results in a csv-file.
    
    Parameters
    ----------
    csv_fh : str
        csv_file with seasonal values (see calc_Y_WP_seasons)
    output_dir : str
        Folder to store results.
    croptype : str
        Name of the crop for which the Y and WP have been calculated.
        
    Returns
    -------
    csv_filename : str
        Path to the new csv-file.
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)  
        
    start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WC_blue, WC_green = read_csv(csv_fh)
    
    years = np.unique(np.array([date.year for date in np.append(start_dates, end_dates)]))
    
    csv_filename = os.path.join(output_dir, 'Yearly_Yields_WPs_{0}.csv'.format(croptype))
    csv_file = open(csv_filename, 'wb')
    writer = csv.writer(csv_file, delimiter=';')
    writer.writerow(["Startdate", "Enddate", "Yield [kg/ha]", "Yield_pr [kg/ha]", "Yield_irr [kg/ha]", "WP [kg/m3]", "WP_blue [kg/m3]", "WP_green [kg/m3]", "WC [km3]", "WC_blue [km3]", "WC_green [km3]"])
    
    for year in years:
        
        starts, ends = (np.array([start_date for start_date, end_date in zip(start_dates, end_dates) if start_date.year == year or end_date.year == year]),
                        np.array([end_date for start_date, end_date in zip(start_dates, end_dates) if start_date.year == year or end_date.year == year]))
    
        boundary = datetime.date(year, 1, 1)
        
        year_length = 366 if calendar.isleap(year) else 365
        
        lengths_total_season = [float(abs((end - start).days)) for start, end in zip(starts, ends)]
        
        lengths_within_year = np.array([min(year_length, abs((boundary - end).days)) - abs(min(0, (boundary - start).days)) for start, end in zip(starts, ends)])
    
        fractions = lengths_within_year / lengths_total_season
        
        y = np.sum(np.array([Y[start_dates == start][0] for start in starts]) * fractions)
        yirr = np.sum(np.array([Yirr[start_dates == start][0] for start in starts]) * fractions)
        ypr = np.sum(np.array([Ypr[start_dates == start][0] for start in starts]) * fractions)
        
        wc = np.sum(np.array([WC[start_dates == start][0] for start in starts]) * fractions)
        wcblue = np.sum(np.array([WC_blue[start_dates == start][0] for start in starts]) * fractions)
        wcgreen = np.sum(np.array([WC_green[start_dates == start][0] for start in starts]) * fractions)
        
        wp = np.average(np.array([WP[start_dates == start][0] for start in starts]), weights = fractions)
        wpblue = np.average(np.array([WPblue[start_dates == start][0] for start in starts]), weights = fractions)
        wpgreen = np.average(np.array([WPgreen[start_dates == start][0] for start in starts]), weights = fractions)
        
        writer.writerow([datetime.date(year,1,1), datetime.date(year,12,31), y, ypr, yirr, wp, wpblue, wpgreen, wc, wcblue, wcgreen])
    
    csv_file.close()
    
    return csv_filename

def import_growing_seasons(csv_fh):
    """
    Reads an csv file with dates, see example for format of the csv file.
    
    Parameters
    ----------
    csv_fh : str
        Filehandle pointing to csv-file
        
    Returns
    -------
    start_dates : ndarray
        List with datetime.date objects
    end_dates : ndarray
        List with datetime.date object
    
    Examples
    --------
    The csv file should be like:
    >>> Start;End<new_line> 
            04/11/2000;17/02/2001<new_line>
            03/05/2001;02/07/2001<new_line>
            29/11/2001;27/02/2002<new_line>
            etc.
    
    """
    start_dates = np.array([])
    end_dates = np.array([])

    with open(csv_fh) as csvfile:
         reader = csv.reader(csvfile, delimiter=';')
         for row in reader:
             if np.all([row[0] != 'Start', row[1] != 'End']):
                 start_dates = np.append(start_dates, datetime.datetime.strptime(row[0], '%d/%m/%Y').date())
                 end_dates = np.append(end_dates, datetime.datetime.strptime(row[1], '%d/%m/%Y').date())
    
    return start_dates, end_dates

def read_csv(csv_fh):
    """
    Reads and csv file generated by the function calc_Y_WP_seasons and returns the 
    values as np.arrays.
    
    Parameters
    ----------
    csv_fh : str
        Filehandle pointing to a csv-file generated by calc_Y_WP_seasons.
        
    Returns
    -------
    start_dates : ndarray
        Array containing datetime.date objects.
    end_dates : ndarray
        Array containing datetime.date objects.      
    Y : ndarray
        Array containing Yield data.
    Yirr : ndarray
        Array containing Yield from irrigation data.
    Ypr : ndarray
        Array containing Yield from precipitation data.
    WP : ndarray
        Array containing Water Productivity data.
    WPblue : ndarray
        Array containing Blue WP data.
    WPgreen : ndarray
        Array containing Green WP data.
    """
    start_dates = np.array([])
    end_dates = np.array([])
    Y = np.array([])
    Yirr = np.array([])
    Ypr = np.array([])
    WP = np.array([])
    WPblue = np.array([])
    WPgreen = np.array([])
    WC = np.array([])
    WC_green = np.array([])
    WC_blue = np.array([])
    
    with open(csv_fh) as csvfile:
         reader = csv.reader(csvfile, delimiter=';')
         for row in reader:
             if np.all([row[2] != 'nan', row[0] != 'Startdate']):
                 try:
                     start_dates = np.append(start_dates, datetime.datetime.strptime(row[0], '%Y-%m-%d').date())
                     end_dates = np.append(end_dates, datetime.datetime.strptime(row[1], '%Y-%m-%d').date())
                 except:
                     start_dates = np.append(start_dates, datetime.datetime.strptime(row[0], '%d/%m/%Y').date())
                     end_dates = np.append(end_dates, datetime.datetime.strptime(row[1], '%d/%m/%Y').date())                     
                 Y = np.append(Y, float(row[2]))
                 Ypr = np.append(Ypr, float(row[3]))
                 Yirr = np.append(Yirr, float(row[4]))
                 WP = np.append(WP, float(row[5]))
                 WPblue = np.append(WPblue, float(row[6]))
                 WPgreen = np.append(WPgreen, float(row[7]))
                 WC = np.append(WC, float(row[8]))
                 WC_blue = np.append(WC_blue, float(row[9]))
                 WC_green = np.append(WC_green, float(row[10]))
                 

    return start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WC_blue, WC_green
    
def calc_Y_WP_seasons(start_dates, end_dates, lu_fh, lu_class, croptype, etgreen_fhs, etgreen_dates, etblue_fhs, etblue_dates, ndm_fhs, ndm_dates, p_fhs, p_dates, output_dir, HIWC_dict, ab = (1.0,1.0)):
    """
    Calculate Yields and WPs per season and save results in a csv-file.
    
    Parameters
    ----------
    start_dates : ndarray
        Array with datetime.date objects specifying the startdates of the growing seasons. See ndvi_profiles.py.
    end_dates : ndarray
        Array with datetime.date objects specifying the enddates of the growing seasons. See ndvi_profiles.py.
    lu_fh : str
        Landuse map.
    lu_class : int
        Landuseclass for which to calculate Y and WP.
    croptype : str
        Name of croptype, should be present in HIWC_dict.keys().
    etgreen_fhs : ndarray
        Array with strings pointing to ETgreen maps.
    etgreen_dates : ndarray
        Array with datetime.date objects corresponding to etgreen_fhs.
    etblue_fhs : ndarray
        Array with strings pointing to ETblue maps.
    etblue_dates : ndarray
        Array with datetime.date objects corresponding to etblue_fhs.
    ndm_fhs : ndarray
        Array with strings pointing to Net-Dry-Matter maps.
    ndm_dates : ndarray
        Array with datetime.date objects corresponding to ndm_fhs.
    p_fhs : ndarray
        Array with strings pointing to P maps.
    p_dates : ndarray
        Array with datetime.date objects corresponding to p_fhs.
    output_dir : str
        Folder to save results
    HIWC_dict : dict
        Dictionary with Harvest indices and Water Contents, see get_dictionaries.get_hi_and_ec().
    ab : tuple, optional
        Two parameters used to split Yield into irrigation and precipitation yield, see split_Yield.
        
    Returns
    -------
    csv_filename : str
        Path to newly created csv-file.        
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)    
    
    csv_filename = os.path.join(output_dir, 'Yields_WPs_{0}.csv'.format(croptype))
    csv_file = open(csv_filename, 'wb')
    writer = csv.writer(csv_file, delimiter=';')
    
    writer.writerow(["Startdate", "Enddate", "Yield [kg/ha]", "Yield_pr [kg/ha]", "Yield_irr [kg/ha]", "WP [kg/m3]", "WP_blue [kg/m3]", "WP_green [kg/m3]", "WC [km3]", "WC_blue [km3]", "WC_green [km3]"])
    for startdate, enddate in zip(start_dates, end_dates):
        Yield, Yield_pr, Yield_irr, Wp, Wp_blue, Wp_green, Wc, Wc_blue, Wc_green = calc_Y_WP_season(startdate, enddate, lu_fh, lu_class, croptype, etgreen_fhs, etgreen_dates, etblue_fhs, etblue_dates, ndm_fhs, ndm_dates, p_fhs, p_dates, HIWC_dict, ab = ab, output_dir = output_dir)
        
        writer.writerow([startdate, enddate, Yield, Yield_pr, Yield_irr, Wp, Wp_blue, Wp_green, Wc, Wc_blue, Wc_green])
    
    csv_file.close()
    return csv_filename

def split_Yield(pfraction, etbfraction, a, b):
    """
    Calculate fractions to split Yield into Yield_precip and Yield _irri.
    
    Parameters
    ----------
    pfraction : ndarray
        Array of Precipitation devided by np.nanmax(P)
    etbfraction : ndarray
        Array of fraction of ETblue of total ET.
    a : float
        Parameter to define the fraction.
    b : float
        Parameter to define the fraction.
        
    Returns
    -------
    fraction : ndarray
        Array of the fraction.
    """
    fraction = -(((etbfraction-1)*a)**2 - ((pfraction-1)*b)**2) + 0.5
    fraction = np.where(fraction > 1.0, 1.0, fraction)
    fraction = np.where(fraction < 0.0, 0.0, fraction)
    return fraction
    
def calc_Y_WP_season(startdate, enddate, lu_fh, lu_class, croptype, etgreen_fhs, etgreen_dates, etblue_fhs, etblue_dates, ndm_fhs, ndm_dates, p_fhs, p_dates, HIWC_dict, ab = (1.0,1.0), output_dir = None):
    """
    Calculate Yields and WPs for one season.
    
    Parameters
    ----------
    startdate : object
        datetime.date object specifying the startdate of the growing season.
    enddate : ndarray
        datetime.date object specifying the enddate of the growing season.
    lu_fh : str
        Landuse map.
    lu_class : int
        Landuseclass for which to calculate Y and WP.
    croptype : str
        Name of croptype, should be present in HIWC_dict.keys().
    etgreen_fhs : ndarray
        Array with strings pointing to ETgreen maps.
    etgreen_dates : ndarray
        Array with datetime.date objects corresponding to etgreen_fhs.
    etblue_fhs : ndarray
        Array with strings pointing to ETblue maps.
    etblue_dates : ndarray
        Array with datetime.date objects corresponding to etblue_fhs.
    ndm_fhs : ndarray
        Array with strings pointing to Net-Dry-Matter maps.
    ndm_dates : ndarray
        Array with datetime.date objects corresponding to ndm_fhs.
    p_fhs : ndarray
        Array with strings pointing to P maps.
    p_dates : ndarray
        Array with datetime.date objects corresponding to p_fhs.
    output_dir : str
        Folder to save results
    HIWC_dict : dict
        Dictionary with Harvest indices and Water Contents, see get_dictionaries.get_hi_and_ec().
    ab : tuple, optional
        Two parameters used to split Yield into irrigation and precipitation yield, see split_Yield.
        
    Returns
    -------
    Yield : float
        The yield for the croptype.
    Yield_pr : float
        The yield_precip for the croptype.
    Yield_irr : float
        The yield_irri for the croptype.
    Wp : float
        The waterproductivity for the croptype.
    Wp_blue : float
        The blue waterproductivity for the croptype.
    Wp_green : float
        The green waterproductivity for the croptype.
    Wc : float
        The water consumption for the croptype.
    Wc_blue : float
        The blue water consumption for the croptype.
    Wc_green : float
        The green water consumption for the croptype.
    """
    common_dates = becgis.CommonDates([etblue_dates, etgreen_dates, p_dates, ndm_dates])
    
    harvest_index = HIWC_dict[croptype][0]  
    moisture_content = HIWC_dict[croptype][1]
    
    current = datetime.date(startdate.year, startdate.month, 1)
    end_month = datetime.date(enddate.year, enddate.month, 1)
    
    req_dates = np.array([current])
    while current < end_month:
        current = current + relativedelta(months = 1)
        req_dates = np.append(req_dates, current)
    
    season_complete = True
    for date in req_dates:
        season_complete = np.all([season_complete, date in common_dates])
        if not season_complete:
            print("{0} missing in input data, skipping this season".format(date))
            
    if season_complete:
    
        fractions = np.ones(np.shape(req_dates))
        
        start_month_length = float(calendar.monthrange(startdate.year, startdate.month)[1])
        end_month_length = float(calendar.monthrange(enddate.year, enddate.month)[1])
        
        fractions[0] = (start_month_length - startdate.day + 1) / start_month_length
        fractions[-1] = (enddate.day -1) / end_month_length
        
        NDMs = np.stack([becgis.OpenAsArray(ndm_fhs[ndm_dates == date][0], nan_values = True) * fraction for date, fraction in zip(req_dates, fractions)], axis=2)
        NDM = np.nansum(NDMs, axis=2)
        del NDMs
        
        ETGREENs = np.stack([becgis.OpenAsArray(etgreen_fhs[etgreen_dates == date][0], nan_values = True) * fraction for date, fraction in zip(req_dates, fractions)], axis=2)
        ETGREEN = np.nansum(ETGREENs, axis=2)
        del ETGREENs
        
        ETBLUEs = np.stack([becgis.OpenAsArray(etblue_fhs[etblue_dates == date][0], nan_values = True) * fraction for date, fraction in zip(req_dates, fractions)], axis=2)
        ETBLUE = np.nansum(ETBLUEs, axis=2)
        del ETBLUEs
        
        Ps = np.stack([becgis.OpenAsArray(p_fhs[p_dates == date][0], nan_values = True) * fraction for date, fraction in zip(req_dates, fractions)], axis=2)
        P = np.nansum(Ps, axis=2)
        del Ps
        
        LULC = becgis.OpenAsArray(lu_fh)
        
        NDM[NDM == 0] = np.nan
        NDM[LULC != lu_class] = ETBLUE[LULC != lu_class] = ETGREEN[LULC != lu_class] =  np.nan
        
        Y = (harvest_index * NDM) / (1 - moisture_content)
        
        etbfraction = ETBLUE / (ETBLUE + ETGREEN)
        pfraction = P / np.nanmax(P)
        fraction = split_Yield(pfraction, etbfraction, ab[0], ab[1])
        
        Yirr = Y * fraction
        Ypr = Y - Yirr

        if output_dir:
            x = y = np.arange(0.0, 1.1, 0.1)
            XX, YY = np.meshgrid(x, y)
            Z = split_Yield(XX,YY, ab[0], ab[1])
            plt.figure(1, figsize = (12,10))
            plt.clf()
            cmap = LinearSegmentedColormap.from_list('mycmap', ['#6bb8cc','#a3db76','#d98d8e'])
            plt.contourf(XX,YY,Z,np.arange(0.0,1.1,0.1), cmap = cmap)
            plt.colorbar(ticks = np.arange(0.0,1.1,0.1), label= 'Yirr as fraction of total Y [-]', boundaries = [0,1])
            plt.xlabel('Normalized Precipitation [-]')
            plt.ylabel('ETblue/ET [-]')
            plt.title('Split Yield into Yirr and Ypr')
            plt.suptitle('Z(X,Y) = -(((Y-1) * a)^2 - ((X-1) * b)^2) + 0.5 with a = {0:.2f} and b = {1:.2f}'.format(ab[0],ab[1]))
            plt.scatter(pfraction, etbfraction, color = 'w', label = croptype, edgecolors = 'k')
            plt.legend()
            plt.xlim((0,1))
            plt.ylim((0,1))
            plt.savefig(os.path.join(output_dir, '{0}_{1}_{2}_cloud.jpg'.format(croptype, req_dates[0], req_dates[-1])))

        Yield = np.nanmean(Y)
        Yield_pr = np.nanmean(Ypr)
        Yield_irr = np.nanmean(Yirr)
        
        Et_blue = np.nanmean(ETBLUE)
        Et_green = np.nanmean(ETGREEN)
        
        areas = becgis.MapPixelAreakm(lu_fh)
        Wc_blue = np.nansum(ETBLUE / 1000**2 * areas)
        Wc_green = np.nansum(ETGREEN / 1000**2 * areas)
        Wc = Wc_blue + Wc_green
        
        areas[LULC != lu_class] = np.nan
        print('{0}: {1} km2'.format(croptype, np.nansum(areas)))
        
        Wp = Yield / ((Et_blue + Et_green) * 10)
        Wp_blue = np.where(Et_blue == 0, [np.nan], [Yield_irr / (Et_blue * 10)])[0]
        Wp_green = np.where(Et_green == 0, [np.nan], [Yield_pr / (Et_green * 10)])[0]
        
    else:
        
        Yield = Yield_pr = Yield_irr = Wp = Wp_blue = Wp_green = Wc = Wc_blue = Wc_green = np.nan
        
    return Yield, Yield_pr, Yield_irr, Wp, Wp_blue, Wp_green, Wc, Wc_blue, Wc_green

def plot_Y_WP(csv_fh, output_dir, croptype = None, catchment_name = None, filetype = 'pdf'):
    """
    Plot yields and water productivities per season or per year.
    
    Parameters
    ----------
    csv_fh : str
        csv-file with yields and wps per season or year, can be generated with calc_Y_WP_year or with calc_Y_WP_seasons.
    output_dir : str
        folder to save graphs.
    croptype : str, optional
        String used to format the graphs.
    catchment_name : str, optional
        String used to format the graphs.
    filetype : str, optional
        filetype, default is pdf, can also choose 'jpg', 'png'.    
    """

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
            
    start_dates, end_dates, Y, Yirr, Ypr, WP, WPblue, WPgreen, WC, WCblue, WCgreen = read_csv(csv_fh)
    
    ordinal_startdates = np.array([date.toordinal() for date in start_dates])
    ordinal_enddates = np.array([date.toordinal() for date in end_dates])
    
    fig = plt.figure(1, figsize = (10,10))
    plt.clf()
    plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
    ax = fig.add_subplot(111)
    ax.bar(start_dates, Yirr, ordinal_enddates-ordinal_startdates, color = '#6bb8cc', label = 'Yield from irrigation', linewidth = 2, edgecolor = 'w')
    ax.bar(start_dates, Ypr, ordinal_enddates-ordinal_startdates, bottom = Yirr, color = '#a3db76', label = 'Yield from precipitation', linewidth = 2, edgecolor = 'w')
    ax.set_title('Seasonal Yield, {0} in {1}'.format(croptype, catchment_name))
    ax.set_xlabel('Time')
    ax.set_ylabel('Yield [kg/ha]')
    [r.set_zorder(10) for r in ax.spines.itervalues()]
    fig.autofmt_xdate()
    ax.legend(loc = 'upper left',fancybox=True, shadow=True)
    ax.set_ylim([0, np.max(Y) * 1.2])
    plt.savefig(os.path.join(output_dir,'{0}_yields.{1}'.format(croptype,filetype)))
    
    ordinal_meandates = np.mean([ordinal_startdates, ordinal_enddates], axis=0)

    fig = plt.figure(2, figsize = (10,10))
    plt.clf()
    plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0)
    ax = fig.add_subplot(111)
    red_patch = mpatches.Patch(color='#d98d8e', label='WP')
    blue_line = mlines.Line2D([], [], color='#6bb8cc', label='WPblue', lw = 3)
    green_line = mlines.Line2D([], [], color='#a3db76', label='WPgreen', lw = 3)
    ax.legend(handles=[red_patch,blue_line, green_line],loc = 'upper left',fancybox=True, shadow=True)
    ax.bar(ordinal_meandates, WPblue, color = 'w', linewidth = 2, edgecolor = 'w', xerr = (ordinal_enddates-ordinal_startdates)/2.2, ecolor = '#6bb8cc', capsize = 0, error_kw = {'lw': 3})
    ax.bar(ordinal_meandates, WPgreen, color = 'w', linewidth = 2, edgecolor = 'w', xerr = (ordinal_enddates-ordinal_startdates)/2.2, ecolor = '#a3db76', capsize = 0, error_kw = {'lw': 3})
    ax.bar(start_dates, WP, ordinal_enddates-ordinal_startdates, color = '#d98d8e', label = 'WP', linewidth = 2, edgecolor = 'w')
    ax.set_title('Seasonal Water Productivity, {0} in {1}'.format(croptype, catchment_name))
    ax.set_ylabel('Water Productivity [kg/m3]')
    ax.set_xlabel('Time')
    ax.set_ylim([0, max(max(WP), max(WPblue), max(WPgreen)) *1.2])
    fig.autofmt_xdate()
    [r.set_zorder(10) for r in ax.spines.itervalues()]
    plt.savefig(os.path.join(output_dir,'{0}_wps.{1}'.format(croptype,filetype)))    
